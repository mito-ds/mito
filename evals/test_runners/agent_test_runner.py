from copy import copy
import pprint
from typing import Dict, List, Literal, Optional, Union
from evals.ai_api_calls.get_open_ai_completion import get_open_ai_completion_code_block, get_open_ai_parsed_response
from evals.asserts.equal_outputs import assert_equal_outputs
from evals.eval_types import AgentFindAndUpdatePromptGenerator, ChatPromptGenerator, ChatTestCase, InlineCodeCompletionPromptGenerator, InlineCodeCompletionTestCase, TestCaseResult
from evals.prompts.agent_find_and_update_prompts import AGENT_PROMPTS
from evals.prompts.chat_prompts import CHAT_PROMPT_GENERATORS
from evals.prompts.inline_code_completion_prompts import INLINE_CODE_COMPLETION_PROMPT_GENERATORS
from evals.test_cases.agent_find_and_update_tests import AGENT_TESTS
from evals.test_cases.agent_find_and_update_tests.simple import AgentFindAndUpdateTestCase, Cell, CellUpdate
from evals.test_cases.chat_tests import CHAT_TESTS
from evals.test_cases.inline_code_completion_tests import INLINE_CODE_COMPLETION_TESTS
from evals.test_runners.utils import exec_code_and_get_globals_and_output
from evals.utils import get_script_from_cells, print_test_case_result_tables
from evals.asserts.equal_globals import assert_equal_globals, get_globals_to_compare

    
def run_agent_tests(test_name: Optional[str], prompt_name: Optional[str], tags: Optional[List[str]], model: Optional[str]):
    _run_code_gen_tests('agent', AGENT_TESTS, AGENT_PROMPTS, test_name, prompt_name, tags, model)

def _run_code_gen_tests(
    test_type: Literal['agent'],
    tests_cases: List[AgentFindAndUpdateTestCase],
    prompt_generators: List[AgentFindAndUpdatePromptGenerator],
    test_name: Optional[str], 
    prompt_name: Optional[str], 
    tags: Optional[List[str]],
    model: Optional[str]
):
    print("Collecting tests...")
    tests_to_run = tests_cases
    if test_name:
        tests_to_run = [test for test in tests_to_run if test.name == test_name]
        if not tests_to_run:
            print(f"No test found with name: {test_name}")
            exit(1)

    # if tags:
    #     tests_to_run = [test for test in tests_to_run if any(tag in tags for tag in test.test_case_core.workflow_tags)]
    #     if not tests_to_run:
    #         print(f"No tests found with tags: {tags}")
    #         exit(1)

    print(f"Collected {len(tests_to_run)} tests")

    # Filter prompts if prompt name provided
    print("Collecting prompts...")
    prompt_generators_to_test = prompt_generators
    if prompt_name:
        prompt_generators_to_test = [prompt for prompt in prompt_generators_to_test if prompt.prompt_name == prompt_name]
        if not prompt_generators_to_test:
            print(f"No prompt found with name: {prompt_name}")
            exit(1)
    print(f"Collected {len(prompt_generators_to_test)} prompts")
    
    # Get the default model if no model is provided
    model = prompt_generators_to_test[0].get_default_model() if model is None else model

    # Mapping from prompt name to test results for each prompt we test
    test_case_results: Dict[str, List[TestCaseResult]] = {}
    for prompt_generator in prompt_generators_to_test:
        test_case_results[prompt_generator.prompt_name] = []
        for test in tests_to_run:
            
            test_case_result = run_code_gen_test(test, prompt_generator, model)
            test_case_results[prompt_generator.prompt_name].append(test_case_result)

    print_test_case_result_tables(test_type, test_case_results, model)

def run_code_gen_test(
        test: AgentFindAndUpdateTestCase, 
        prompt_generator: AgentFindAndUpdatePromptGenerator,
        model: str
) -> TestCaseResult:
    print(f"\n\033[1mRunning test: {test.name}\033[0m")

    # Construct the prompt 
    prompt = prompt_generator.get_prompt(test.user_input, test.initial_notebook_state)
        
    # Get the code generated by the LLM
    ai_generated_cell_update = get_open_ai_parsed_response(prompt, model, CellUpdate)
    
    print("AI UPDATE")
    print(ai_generated_cell_update)

    initial_notebook_state_copy = copy(test.initial_notebook_state)
    
    expected_code = get_script_with_cell_update_applied(test.cell_update, initial_notebook_state_copy)
    actual_code = get_script_with_cell_update_applied(ai_generated_cell_update, test.initial_notebook_state)

    # Execute the code and check if they produce the same results
    try:
        expected_globals, expected_output = exec_code_and_get_globals_and_output(expected_code)
        actual_globals, actual_output = exec_code_and_get_globals_and_output(actual_code)
    except Exception as e:
        # Fail early if we can't execute the code
        print(f"Failed to execute code with error: {e}")
        print(f"AI Generated Code: {ai_generated_cell_update}")
        print(f"Actual Code: {actual_code}")
        print(f"Expected Code: {expected_code}")
        return TestCaseResult(test=test, passed=False)

    equal_globals = assert_equal_globals(expected_globals, actual_globals)
    equal_outputs = assert_equal_outputs(expected_output, actual_output)

    passed = equal_globals and equal_outputs

    # if not passed:
        # debug_failed_test_case(test, ai_generated_code, actual_code, expected_code, equal_globals, equal_outputs, expected_globals, actual_globals, expected_output, actual_output)

    return TestCaseResult(test=test, passed=passed)


def debug_failed_test_case(
        test: Union[ChatTestCase, InlineCodeCompletionTestCase],
        ai_generated_code: str, 
        actual_code: str,
        expected_code: str, 
        equal_globals: bool, 
        equal_outputs: bool, 
        expected_globals: Dict[str, str],
        actual_globals: Dict[str, str],
        expected_output: str,
        actual_output: str,
    ) -> None:


    print(f"AI Generated Code: {ai_generated_code}")
    print(f"Actual Code: {actual_code}")
    print(f"Expected Code: {expected_code}")
    print(f"Equal Globals: {equal_globals}")
    print(f"Equal Outputs: {equal_outputs}")
    if not equal_outputs:
        print(f"Expected Output: {expected_output}")
        print(f"Actual Output: {actual_output}")


def get_script_with_cell_update_applied(cell_update: CellUpdate, initial_notebook_state: List[Cell]) -> str:
    
    # Return the notebook as one chunk of code with the cell update applied
    for cell in initial_notebook_state:
        if cell.id == cell_update.id:
            cell.code = cell_update.code
            
    code_cells = [cell.code for cell in initial_notebook_state]
    new_code = "\n".join(code_cells)
    
    return new_code